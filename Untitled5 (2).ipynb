{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0oLef5lU7lw"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import time\n",
        "import mediapipe as mp\n",
        "from ultralytics import YOLO\n",
        "import math\n",
        "\n",
        "# MediaPipe hazırla\n",
        "drawing = mp.solutions.drawing_utils\n",
        "faceDetection = mp.solutions.face_detection.FaceDetection(0.7)\n",
        "hands = mp.solutions.hands.Hands(False, max_num_hands=2, min_detection_confidence=0.7)\n",
        "faceMesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True)\n",
        "\n",
        "# YOLOv8 modelini yükle\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Kamera başlat\n",
        "cap = cv2.VideoCapture(0)\n",
        "prev_time = 0\n",
        "\n",
        "# Göz kırpma sayacı\n",
        "blink_count = 0\n",
        "blink_state = False\n",
        "\n",
        "# Göz landmark indeksleri\n",
        "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE = [263, 387, 385, 362, 380, 373]\n",
        "\n",
        "# Ağız landmark indeksleri\n",
        "MOUTH_OUTER = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291]\n",
        "MOUTH_TOP = 13\n",
        "MOUTH_BOTTOM = 14\n",
        "MOUTH_LEFT = 61\n",
        "MOUTH_RIGHT = 291\n",
        "\n",
        "\n",
        "def calc_distance(p1, p2):\n",
        "    return math.hypot(p1.x - p2.x, p1.y - p2.y)\n",
        "\n",
        "\n",
        "def eye_aspect_ratio(landmarks, eye_indices):\n",
        "    vertical1 = calc_distance(landmarks[eye_indices[1]], landmarks[eye_indices[5]])\n",
        "    vertical2 = calc_distance(landmarks[eye_indices[2]], landmarks[eye_indices[4]])\n",
        "    horizontal = calc_distance(landmarks[eye_indices[0]], landmarks[eye_indices[3]])\n",
        "    return (vertical1 + vertical2) / (2.0 * horizontal)\n",
        "\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    imgRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    h, w, _ = frame.shape\n",
        "\n",
        "    curr_time = time.time()\n",
        "    fps = 1 / (curr_time - prev_time)\n",
        "    prev_time = curr_time\n",
        "\n",
        "    resultsFace = faceDetection.process(imgRGB)\n",
        "    totalFingers = 0\n",
        "    current_expression = \"\"\n",
        "\n",
        "    if resultsFace.detections:\n",
        "        for detection in resultsFace.detections:\n",
        "            bboxC = detection.location_data.relative_bounding_box\n",
        "            x, y = int(bboxC.xmin * w), int(bboxC.ymin * h)\n",
        "            box_w, box_h = int(bboxC.width * w), int(bboxC.height * h)\n",
        "            cv2.rectangle(frame, (x, y), (x + box_w, y + box_h), (255, 0, 255), 2)\n",
        "\n",
        "            resultsHands = hands.process(imgRGB)\n",
        "            if resultsHands.multi_hand_landmarks:\n",
        "                for handLms in resultsHands.multi_hand_landmarks:\n",
        "                    drawing.draw_landmarks(frame, handLms, mp.solutions.hands.HAND_CONNECTIONS)\n",
        "\n",
        "                    thumb_tip = handLms.landmark[4]\n",
        "                    thumb_ip = handLms.landmark[3]\n",
        "\n",
        "                    fingers_up = []\n",
        "                    tips = [8, 12, 16, 20]\n",
        "\n",
        "                    if thumb_tip.x < thumb_ip.x:\n",
        "                        fingers_up.append(1)\n",
        "                    else:\n",
        "                        fingers_up.append(0)\n",
        "\n",
        "                    for tip in tips:\n",
        "                        if handLms.landmark[tip].y < handLms.landmark[tip - 2].y:\n",
        "                            fingers_up.append(1)\n",
        "                        else:\n",
        "                            fingers_up.append(0)\n",
        "\n",
        "                    totalFingers = sum(fingers_up)\n",
        "\n",
        "    faceMeshResults = faceMesh.process(imgRGB)\n",
        "    if faceMeshResults.multi_face_landmarks:\n",
        "        for faceLms in faceMeshResults.multi_face_landmarks:\n",
        "            landmarks = faceLms.landmark\n",
        "\n",
        "            left_ear = eye_aspect_ratio(landmarks, LEFT_EYE)\n",
        "            right_ear = eye_aspect_ratio(landmarks, RIGHT_EYE)\n",
        "            avg_ear = (left_ear + right_ear) / 2.0\n",
        "\n",
        "            if avg_ear < 0.23:\n",
        "                if not blink_state:\n",
        "                    blink_count += 1\n",
        "                    blink_state = True\n",
        "            else:\n",
        "                blink_state = False\n",
        "\n",
        "            mouth_points = []\n",
        "            for idx in MOUTH_OUTER:\n",
        "                x_mouth = int(landmarks[idx].x * w)\n",
        "                y_mouth = int(landmarks[idx].y * h)\n",
        "                mouth_points.append((x_mouth, y_mouth))\n",
        "\n",
        "            for i in range(len(mouth_points)):\n",
        "                cv2.line(frame, mouth_points[i], mouth_points[(i + 1) % len(mouth_points)], (255, 0, 0), 2)\n",
        "\n",
        "            top_mouth = landmarks[MOUTH_TOP]\n",
        "            bottom_mouth = landmarks[MOUTH_BOTTOM]\n",
        "            left_mouth = landmarks[MOUTH_LEFT]\n",
        "            right_mouth = landmarks[MOUTH_RIGHT]\n",
        "\n",
        "            top_mouth_pos = (int(top_mouth.x * w), int(top_mouth.y * h))\n",
        "            bottom_mouth_pos = (int(bottom_mouth.x * w), int(bottom_mouth.y * h))\n",
        "            left_mouth_pos = (int(left_mouth.x * w), int(left_mouth.y * h))\n",
        "            right_mouth_pos = (int(right_mouth.x * w), int(right_mouth.y * h))\n",
        "\n",
        "            mouth_open_dist = math.hypot(top_mouth_pos[0] - bottom_mouth_pos[0],\n",
        "                                         top_mouth_pos[1] - bottom_mouth_pos[1])\n",
        "            mouth_width = math.hypot(left_mouth_pos[0] - right_mouth_pos[0],\n",
        "                                     left_mouth_pos[1] - right_mouth_pos[1])\n",
        "            mouth_ratio = mouth_open_dist / mouth_width\n",
        "\n",
        "            if mouth_ratio > 0.25:\n",
        "                current_expression = \"mutlu\"\n",
        "                color = (0, 255, 0)\n",
        "            elif mouth_ratio < 0.05:\n",
        "                current_expression = \"somurtma\"\n",
        "                color = (0, 0, 255)\n",
        "            else:\n",
        "                current_expression = \"normal\"\n",
        "                color = (0, 255, 255)\n",
        "\n",
        "    # YOLO ile nesne tespiti\n",
        "    results = model(frame, stream=True)\n",
        "    for r in results:\n",
        "        for box in r.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            cls = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            label = model.names[cls]\n",
        "\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, f'{label} {int(conf * 100)}%', (x1, y1 - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "    cv2.putText(frame, f'fps: {int(fps)}', (w - 620, 33), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "    cv2.putText(frame, f'kirpma: {blink_count}', (w - 620, 53), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "    cv2.putText(frame, f'parmak: {totalFingers}', (w - 620, 73), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "    if current_expression:\n",
        "        cv2.putText(frame, f'ifade: {current_expression}', (w - 620, 93), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255),\n",
        "                    2)\n",
        "\n",
        "    cv2.imshow(\"AI Proje - YOLO + MediaPipe + Göz + Ağız + Parmak\", frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ]
}